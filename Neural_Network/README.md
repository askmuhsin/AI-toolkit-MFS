# An artificial neural network (ANN) is an interconnected group of nodes, akin to the vast network of neurons in a brain.
<p>In the mathematical theory of artificial neural networks, the universal approximation theorem states that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of Rn, under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters.</p>
<p>Read more : <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">Universal_approximation_theorem</a></p>
<br></br>
<p>More discussions on the following papers will be added here : </p>
<ul>
<li>McCulloch and Pitts, 1943</li>
<li>Hebb, 1949</li>
<li>Rosenblatt, 1958</li>
<li>Widrow and Hoff, 1960</li>
<li>Minsky and Papert, 1969</li>
<li>Rumelhart, Hinton and Williams, 1986</li>
</ul>
<br></br>
<p>Codings that are planning to be covered are : </p>
<li>Simple SLP, using Perceptron Convergence Theorem</li>
<li>MLP using Backpropagation (XOR problem)</li>
<li>Regression problem with 2 inputs. (Flood prediction from historic data (water level and flow rate) output will be an aletrness level)</li>
<li>Classification of handwritten numerals</li>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p>.</p>
<p><br></br></p>
